{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6fe01d-b3cf-454d-b245-54be3b0c437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551059a",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b90cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9388874-631d-456d-9d89-8279e1114941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset : news_setopati_preprocessed_1.csv is from मंसिर २९, २०८० to जेठ २०, २०७५ from setopati website in politics section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b440133f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>सर्वोच्चमा प्रस्तावित न्यायाधीश अब्दुल अजिज मु...</td>\n",
       "      <td>सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...</td>\n",
       "      <td>https://www.setopati.com/politics/318075</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>सर्वोच्चमा प्रस्तावित न्यायाधीश अब्दुल अजिज मु...</td>\n",
       "      <td>सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...</td>\n",
       "      <td>https://www.setopati.com/politics/318075</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>'अदालतले आदेश उल्ट्यायो, आत्मालोचना गर्नुहुन्न?'</td>\n",
       "      <td>सर्वोच्च अदालतका लागि प्रस्तावित न्यायाधीश सार...</td>\n",
       "      <td>https://www.setopati.com/politics/318066</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>संसदीय सुनुवाइ समितिमा सांसदहरूले नै राख्दैनन्...</td>\n",
       "      <td>सर्वोच्च अदालतका प्रधानन्यायाधीश न्यायाधीश संव...</td>\n",
       "      <td>https://www.setopati.com/politics/318072</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>'समुदायमा कांग्रेस' अभियान पुस १६ गतेदेखि सुरू...</td>\n",
       "      <td>नेपाली कांग्रेसले पुस गतेदेखि माघ गतेसम्म समुद...</td>\n",
       "      <td>https://www.setopati.com/politics/318070</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942</th>\n",
       "      <td>politics</td>\n",
       "      <td>आइतबार, जेठ २०, २०७५</td>\n",
       "      <td>विपी राजमार्गमा मनोमानीः रूट परमिट दिने निर्णय...</td>\n",
       "      <td>काठमाडौंदेखि वर्दिबाससम्मको विपि राजमार्गमा ठू...</td>\n",
       "      <td>https://www.setopati.com/politics/161202</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38943</th>\n",
       "      <td>politics</td>\n",
       "      <td>आइतबार, जेठ २०, २०७५</td>\n",
       "      <td>सांसदले अर्थमन्त्रीलाई सोधे : जिडिपी वृद्धि भन...</td>\n",
       "      <td>नेपाली कांग्रेसकी सांसद चित्रलेखा यादवले संसद ...</td>\n",
       "      <td>https://www.setopati.com/politics/161201</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38944</th>\n",
       "      <td>politics</td>\n",
       "      <td>आइतबार, जेठ २०, २०७५</td>\n",
       "      <td>छिरिङ वाङ्गेल पुर्पक्षका लागि जेल चलान</td>\n",
       "      <td>साढे किलो सुन र सनम शाक्यको हत्याका मुख्य अभिय...</td>\n",
       "      <td>https://www.setopati.com/politics/161195</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38945</th>\n",
       "      <td>politics</td>\n",
       "      <td>आइतबार, जेठ २०, २०७५</td>\n",
       "      <td>अर्थमन्त्रीले प्रत्यक्ष चुनाव लडेमात्र सांसदको...</td>\n",
       "      <td>नेपाली कांग्रेसका सांसद प्रदीप गिरिले अर्थमन्त...</td>\n",
       "      <td>https://www.setopati.com/politics/161191</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38946</th>\n",
       "      <td>politics</td>\n",
       "      <td>आइतबार, जेठ २०, २०७५</td>\n",
       "      <td>यी हुन् आजका मन्त्रिपरिषद् बैठकका निर्णयहरू</td>\n",
       "      <td>बहुपक्षीय प्राविधिक तथा आर्थिक सहयोगका लागि बं...</td>\n",
       "      <td>https://www.setopati.com/politics/161187</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38947 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          topic                      date  \\\n",
       "0      politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "1      politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "2      politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "3      politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "4      politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "...         ...                       ...   \n",
       "38942  politics      आइतबार, जेठ २०, २०७५   \n",
       "38943  politics      आइतबार, जेठ २०, २०७५   \n",
       "38944  politics      आइतबार, जेठ २०, २०७५   \n",
       "38945  politics      आइतबार, जेठ २०, २०७५   \n",
       "38946  politics      आइतबार, जेठ २०, २०७५   \n",
       "\n",
       "                                                   title  \\\n",
       "0      सर्वोच्चमा प्रस्तावित न्यायाधीश अब्दुल अजिज मु...   \n",
       "1      सर्वोच्चमा प्रस्तावित न्यायाधीश अब्दुल अजिज मु...   \n",
       "2       'अदालतले आदेश उल्ट्यायो, आत्मालोचना गर्नुहुन्न?'   \n",
       "3      संसदीय सुनुवाइ समितिमा सांसदहरूले नै राख्दैनन्...   \n",
       "4      'समुदायमा कांग्रेस' अभियान पुस १६ गतेदेखि सुरू...   \n",
       "...                                                  ...   \n",
       "38942  विपी राजमार्गमा मनोमानीः रूट परमिट दिने निर्णय...   \n",
       "38943  सांसदले अर्थमन्त्रीलाई सोधे : जिडिपी वृद्धि भन...   \n",
       "38944             छिरिङ वाङ्गेल पुर्पक्षका लागि जेल चलान   \n",
       "38945  अर्थमन्त्रीले प्रत्यक्ष चुनाव लडेमात्र सांसदको...   \n",
       "38946        यी हुन् आजका मन्त्रिपरिषद् बैठकका निर्णयहरू   \n",
       "\n",
       "                                                    body  \\\n",
       "0      सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...   \n",
       "1      सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...   \n",
       "2      सर्वोच्च अदालतका लागि प्रस्तावित न्यायाधीश सार...   \n",
       "3      सर्वोच्च अदालतका प्रधानन्यायाधीश न्यायाधीश संव...   \n",
       "4      नेपाली कांग्रेसले पुस गतेदेखि माघ गतेसम्म समुद...   \n",
       "...                                                  ...   \n",
       "38942  काठमाडौंदेखि वर्दिबाससम्मको विपि राजमार्गमा ठू...   \n",
       "38943  नेपाली कांग्रेसकी सांसद चित्रलेखा यादवले संसद ...   \n",
       "38944  साढे किलो सुन र सनम शाक्यको हत्याका मुख्य अभिय...   \n",
       "38945  नेपाली कांग्रेसका सांसद प्रदीप गिरिले अर्थमन्त...   \n",
       "38946  बहुपक्षीय प्राविधिक तथा आर्थिक सहयोगका लागि बं...   \n",
       "\n",
       "                                           link    source  \n",
       "0      https://www.setopati.com/politics/318075  Setopati  \n",
       "1      https://www.setopati.com/politics/318075  Setopati  \n",
       "2      https://www.setopati.com/politics/318066  Setopati  \n",
       "3      https://www.setopati.com/politics/318072  Setopati  \n",
       "4      https://www.setopati.com/politics/318070  Setopati  \n",
       "...                                         ...       ...  \n",
       "38942  https://www.setopati.com/politics/161202  Setopati  \n",
       "38943  https://www.setopati.com/politics/161201  Setopati  \n",
       "38944  https://www.setopati.com/politics/161195  Setopati  \n",
       "38945  https://www.setopati.com/politics/161191  Setopati  \n",
       "38946  https://www.setopati.com/politics/161187  Setopati  \n",
       "\n",
       "[38947 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/news-setopati/news_setopati_preprocessed_1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39dfe9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>सर्वोच्चमा प्रस्तावित न्यायाधीश अब्दुल अजिज मु...</td>\n",
       "      <td>सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...</td>\n",
       "      <td>https://www.setopati.com/politics/318075</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>सर्वोच्चमा प्रस्तावित न्यायाधीश अब्दुल अजिज मु...</td>\n",
       "      <td>सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...</td>\n",
       "      <td>https://www.setopati.com/politics/318075</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>'अदालतले आदेश उल्ट्यायो, आत्मालोचना गर्नुहुन्न?'</td>\n",
       "      <td>सर्वोच्च अदालतका लागि प्रस्तावित न्यायाधीश सार...</td>\n",
       "      <td>https://www.setopati.com/politics/318066</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>संसदीय सुनुवाइ समितिमा सांसदहरूले नै राख्दैनन्...</td>\n",
       "      <td>सर्वोच्च अदालतका प्रधानन्यायाधीश न्यायाधीश संव...</td>\n",
       "      <td>https://www.setopati.com/politics/318072</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics</td>\n",
       "      <td>शुक्रबार, मंसिर २९, २०८०</td>\n",
       "      <td>'समुदायमा कांग्रेस' अभियान पुस १६ गतेदेखि सुरू...</td>\n",
       "      <td>नेपाली कांग्रेसले पुस गतेदेखि माघ गतेसम्म समुद...</td>\n",
       "      <td>https://www.setopati.com/politics/318070</td>\n",
       "      <td>Setopati</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                      date  \\\n",
       "0  politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "1  politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "2  politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "3  politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "4  politics  शुक्रबार, मंसिर २९, २०८०   \n",
       "\n",
       "                                               title  \\\n",
       "0  सर्वोच्चमा प्रस्तावित न्यायाधीश अब्दुल अजिज मु...   \n",
       "1  सर्वोच्चमा प्रस्तावित न्यायाधीश अब्दुल अजिज मु...   \n",
       "2   'अदालतले आदेश उल्ट्यायो, आत्मालोचना गर्नुहुन्न?'   \n",
       "3  संसदीय सुनुवाइ समितिमा सांसदहरूले नै राख्दैनन्...   \n",
       "4  'समुदायमा कांग्रेस' अभियान पुस १६ गतेदेखि सुरू...   \n",
       "\n",
       "                                                body  \\\n",
       "0  सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...   \n",
       "1  सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...   \n",
       "2  सर्वोच्च अदालतका लागि प्रस्तावित न्यायाधीश सार...   \n",
       "3  सर्वोच्च अदालतका प्रधानन्यायाधीश न्यायाधीश संव...   \n",
       "4  नेपाली कांग्रेसले पुस गतेदेखि माघ गतेसम्म समुद...   \n",
       "\n",
       "                                       link    source  \n",
       "0  https://www.setopati.com/politics/318075  Setopati  \n",
       "1  https://www.setopati.com/politics/318075  Setopati  \n",
       "2  https://www.setopati.com/politics/318066  Setopati  \n",
       "3  https://www.setopati.com/politics/318072  Setopati  \n",
       "4  https://www.setopati.com/politics/318070  Setopati  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52f5db8f-8d5f-40b8-88c4-5a1a461477d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38947"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4c00f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>सर्वोच्च अदालतका लागि प्रस्तावित न्यायाधीश सार...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>सर्वोच्च अदालतका प्रधानन्यायाधीश न्यायाधीश संव...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>नेपाली कांग्रेसले पुस गतेदेखि माघ गतेसम्म समुद...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942</th>\n",
       "      <td>काठमाडौंदेखि वर्दिबाससम्मको विपि राजमार्गमा ठू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38943</th>\n",
       "      <td>नेपाली कांग्रेसकी सांसद चित्रलेखा यादवले संसद ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38944</th>\n",
       "      <td>साढे किलो सुन र सनम शाक्यको हत्याका मुख्य अभिय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38945</th>\n",
       "      <td>नेपाली कांग्रेसका सांसद प्रदीप गिरिले अर्थमन्त...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38946</th>\n",
       "      <td>बहुपक्षीय प्राविधिक तथा आर्थिक सहयोगका लागि बं...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38947 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body\n",
       "0      सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...\n",
       "1      सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...\n",
       "2      सर्वोच्च अदालतका लागि प्रस्तावित न्यायाधीश सार...\n",
       "3      सर्वोच्च अदालतका प्रधानन्यायाधीश न्यायाधीश संव...\n",
       "4      नेपाली कांग्रेसले पुस गतेदेखि माघ गतेसम्म समुद...\n",
       "...                                                  ...\n",
       "38942  काठमाडौंदेखि वर्दिबाससम्मको विपि राजमार्गमा ठू...\n",
       "38943  नेपाली कांग्रेसकी सांसद चित्रलेखा यादवले संसद ...\n",
       "38944  साढे किलो सुन र सनम शाक्यको हत्याका मुख्य अभिय...\n",
       "38945  नेपाली कांग्रेसका सांसद प्रदीप गिरिले अर्थमन्त...\n",
       "38946  बहुपक्षीय प्राविधिक तथा आर्थिक सहयोगका लागि बं...\n",
       "\n",
       "[38947 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unprocessed_data = pd.DataFrame(columns=['body'])\n",
    "unprocessed_data[\"body\"] = df[\"body\"].apply(str)\n",
    "unprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502191d8",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d0f3bd-d5a3-48af-a4f4-73ee86def937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "nepali_stopwords = open(\"../resources/stopwords.txt\", \"r\")\n",
    "stopwords = nepali_stopwords.read().split()\n",
    "# print(stopwords)\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f39ed833-bd93-43f1-a34b-2db37fe12559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>सर्वोच्च अदालतका प्रस्तावित न्यायाधीश सारंगा स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>सर्वोच्च अदालतका प्रधानन्यायाधीश न्यायाधीश संव...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>नेपाली कांग्रेसले पुस गतेदेखि माघ गतेसम्म समुद...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942</th>\n",
       "      <td>काठमाडौंदेखि वर्दिबाससम्मको विपि राजमार्गमा ठू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38943</th>\n",
       "      <td>नेपाली कांग्रेसकी सांसद चित्रलेखा यादवले संसद ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38944</th>\n",
       "      <td>साढे किलो सुन सनम शाक्यको हत्याका अभियुक्त भनि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38945</th>\n",
       "      <td>नेपाली कांग्रेसका सांसद प्रदीप गिरिले अर्थमन्त...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38946</th>\n",
       "      <td>बहुपक्षीय प्राविधिक आर्थिक सहयोगका बंगालको खाड...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38947 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body\n",
       "0      सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...\n",
       "1      सर्वोच्च अदालतमा प्रस्तावित न्यायाधीश अब्दुल अ...\n",
       "2      सर्वोच्च अदालतका प्रस्तावित न्यायाधीश सारंगा स...\n",
       "3      सर्वोच्च अदालतका प्रधानन्यायाधीश न्यायाधीश संव...\n",
       "4      नेपाली कांग्रेसले पुस गतेदेखि माघ गतेसम्म समुद...\n",
       "...                                                  ...\n",
       "38942  काठमाडौंदेखि वर्दिबाससम्मको विपि राजमार्गमा ठू...\n",
       "38943  नेपाली कांग्रेसकी सांसद चित्रलेखा यादवले संसद ...\n",
       "38944  साढे किलो सुन सनम शाक्यको हत्याका अभियुक्त भनि...\n",
       "38945  नेपाली कांग्रेसका सांसद प्रदीप गिरिले अर्थमन्त...\n",
       "38946  बहुपक्षीय प्राविधिक आर्थिक सहयोगका बंगालको खाड...\n",
       "\n",
       "[38947 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Remove unwanted characters\n",
    "Remove stop words \n",
    "'''\n",
    "import re\n",
    "def string_manipulation(unprocessed_data)  : \n",
    "    unprocessed_data['body'] = unprocessed_data['body'].apply(lambda x: re.sub('[।(),०-९<<?!,—,–,/,’,‘,:,\\u200d]', '', x))\n",
    "    unprocessed_data['body'] = unprocessed_data['body'].apply(lambda x: \" \".join([i.replace('\\n', '').replace('\\t', '').replace(\"\\\"\",'') for i in x.split() if i not in (stopwords) and i != ' ']))\n",
    "    return unprocessed_data\n",
    "\n",
    "processed_data = string_manipulation(unprocessed_data)\n",
    "processed_data\n",
    "\n",
    "# processed_data = pd.DataFrame(columns=['body'])\n",
    "# processed_data[\"body\"] = df[\"body\"]\n",
    "# processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e39e20-08d3-4df7-9389-75b062f39eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepalitokenizer import NepaliTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a24b96f-82a5-4a48-9e78-ae2dbc19273f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[सर्वोच्च, अदालतमा, प्रस्तावित, न्यायाधीश, अब्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[सर्वोच्च, अदालतमा, प्रस्तावित, न्यायाधीश, अब्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[सर्वोच्च, अदालतका, प्रस्तावित, न्यायाधीश, सार...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[सर्वोच्च, अदालतका, प्रधानन्यायाधीश, न्यायाधीश...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[नेपाली, कांग्रेसले, पुस, गतेदेखि, माघ, गतेसम्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942</th>\n",
       "      <td>[काठमाडौंदेखि, वर्दिबाससम्मको, विपि, राजमार्गम...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38943</th>\n",
       "      <td>[नेपाली, कांग्रेसकी, सांसद, चित्रलेखा, यादवले,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38944</th>\n",
       "      <td>[साढे, किलो, सुन, सनम, शाक्यको, हत्याका, अभियु...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38945</th>\n",
       "      <td>[नेपाली, कांग्रेसका, सांसद, प्रदीप, गिरिले, अर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38946</th>\n",
       "      <td>[बहुपक्षीय, प्राविधिक, आर्थिक, सहयोगका, बंगालक...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38947 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body\n",
       "0      [सर्वोच्च, अदालतमा, प्रस्तावित, न्यायाधीश, अब्...\n",
       "1      [सर्वोच्च, अदालतमा, प्रस्तावित, न्यायाधीश, अब्...\n",
       "2      [सर्वोच्च, अदालतका, प्रस्तावित, न्यायाधीश, सार...\n",
       "3      [सर्वोच्च, अदालतका, प्रधानन्यायाधीश, न्यायाधीश...\n",
       "4      [नेपाली, कांग्रेसले, पुस, गतेदेखि, माघ, गतेसम्...\n",
       "...                                                  ...\n",
       "38942  [काठमाडौंदेखि, वर्दिबाससम्मको, विपि, राजमार्गम...\n",
       "38943  [नेपाली, कांग्रेसकी, सांसद, चित्रलेखा, यादवले,...\n",
       "38944  [साढे, किलो, सुन, सनम, शाक्यको, हत्याका, अभियु...\n",
       "38945  [नेपाली, कांग्रेसका, सांसद, प्रदीप, गिरिले, अर...\n",
       "38946  [बहुपक्षीय, प्राविधिक, आर्थिक, सहयोगका, बंगालक...\n",
       "\n",
       "[38947 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tokenizing the corpus \n",
    "'''\n",
    "tokenize = NepaliTokenizer()\n",
    "processed_data[\"body\"] = processed_data[\"body\"].apply(tokenize.tokenizer)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3346f941-fc95-4b0a-a0be-8573e34308b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowballstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ba5723-4409-4144-bbf1-15ee3bbba56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stemming & StopWord removal after Stemming\n",
    "'''\n",
    "stemmer = snowballstemmer.NepaliStemmer()\n",
    "\n",
    "def get_stem(words):\n",
    "    global stemmer\n",
    "    new_list = stemmer.stemWords(words)\n",
    "    return new_list\n",
    "\n",
    "def clean_data(words):\n",
    "    new_list = []\n",
    "    for word in words:\n",
    "        if len(word)>2 and word not in stopwords:\n",
    "            new_list.append(word)\n",
    "\n",
    "    return new_list\n",
    "        \n",
    "# ans = get_stem([\"फिल्मी\", \"अनुराग\", \"वर्ष\", \"अघिसम्म\", \"उनका\", \"बलिउड\"])\n",
    "# ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88abd89b-e064-4aca-b8ff-3a58f5ebc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['body'] = processed_data['body'].apply(lambda x : get_stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be13fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['body'] = processed_data['body'].apply(lambda x : clean_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9b49fb7-1d5a-45b1-b207-f7e998137f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_list = processed_data['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c0248e-f8bf-4210-be60-9db77b844971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [सर्वोच्च, अदालत, प्रस्तावित, न्यायाधीश, अब्दु...\n",
       "1        [सर्वोच्च, अदालत, प्रस्तावित, न्यायाधीश, अब्दु...\n",
       "2        [सर्वोच्च, अदालत, प्रस्तावित, न्यायाधीश, सारंग...\n",
       "3        [सर्वोच्च, अदालत, प्रधानन्यायाधीश, न्यायाधीश, ...\n",
       "4        [नेपाली, कांग्रेस, पुस, गते, माघ, गतेसम्म, समु...\n",
       "                               ...                        \n",
       "38942    [काठमाडौं, वर्दिबाससम्म, विपि, राजमार्ग, ठूला,...\n",
       "38943    [नेपाली, कांग्रेस, सांसद, चित्रलेखा, यादव, संस...\n",
       "38944    [साढे, किलो, सुन, सनम, शाक्य, हत्या, अभियुक्त,...\n",
       "38945    [नेपाली, कांग्रेस, सांसद, प्रदीप, गिरि, अर्थमन...\n",
       "38946    [बहुपक्षीय, प्राविधिक, आर्थिक, सहयोग, बंगाल, ख...\n",
       "Name: body, Length: 38947, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b0554a",
   "metadata": {},
   "source": [
    "### Visualization and Analysis of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af744a5-982d-4948-a0da-d787ea7ac97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFinding the frequency Distribution of Words\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Finding the frequency Distribution of Words\n",
    "'''\n",
    "# words_list = []\n",
    "# for sentence in processed_data_list:\n",
    "#     words_list.extend(sentence)\n",
    "# freq_dist = nltk.FreqDist(words_list)\n",
    "# freq_dist.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c40de29-d05f-4293-a6b8-39645dcf02fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVisualization of Most Frequency \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Visualization of Most Frequency \n",
    "'''\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.font_manager import FontProperties\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# nepali_font = FontProperties(fname = 'Mangal.ttf')\n",
    "# temp = pd.DataFrame(freq_dist.most_common(30),  columns=['word', 'count'])\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# sns.barplot(x='word', y='count', \n",
    "#             data=temp, ax=ax)\n",
    "# plt.title(\"Top words\")\n",
    "# plt.xticks(rotation='vertical',fontproperties=nepali_font);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4f5d550-c5c7-466c-b19f-1bf418382551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nForming Word Cloud\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Forming Word Cloud\n",
    "'''\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# from wordcloud import WordCloud\n",
    "# import wordcloud\n",
    "# # creation of wordcloud\n",
    "# wcloud_fig = WordCloud(colormap='viridis', width=300, height=200, font_path=\"./Mangal.ttf\").generate_from_frequencies(freq_dist)\n",
    "\n",
    "# # plotting the wordcloud\n",
    "# plt.figure(figsize=(10,7), frameon=True )\n",
    "\n",
    "# plt.imshow(wcloud_fig, interpolation  = 'bilinear')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6b440",
   "metadata": {},
   "source": [
    "### Preparation for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "066e61c3-95c7-4b3a-8379-b440d19f86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf92be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3c559e8-7a80-4206-a3a3-9c22a832a17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<220816 unique tokens: ['अजिज', 'अदालत', 'अध्यक्षता', 'अनुमोदन', 'अन्तरिम']...>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Representing the Corpus in dictionary: \n",
    "{unique_id : word}\n",
    "'''\n",
    "id2word = corpora.Dictionary(processed_data_list)\n",
    "print(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bac4bf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nChecking dictionary created\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Checking dictionary created\n",
    "'''\n",
    "# count = 0\n",
    "# for k, v in id2word.iteritems():\n",
    "#     print(k, v)\n",
    "#     count += 1\n",
    "#     if count > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "007a97ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remove very rare and very common words:\n",
    "\n",
    "- words appearing less than 15 times\n",
    "- words appearing in more than 10% of all documents\n",
    "'''\n",
    "# id2word.filter_extremes(no_below=15, no_above=0.1, keep_n=100000)\n",
    "id2word.filter_extremes(no_below=15, no_above=0.1, keep_n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49f80654-086a-421a-add1-85dbfaea5efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<18580 unique tokens: ['अजिज', 'अध्यक्षता', 'अनुमोदन', 'अन्तरिम', 'अब्दुल']...>\n"
     ]
    }
   ],
   "source": [
    "print(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df732959-4261-4f53-958b-51db62eb0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary\n",
    "# id2word.save('../saved_model/dictionary_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e7e2f65-7455-4845-8885-bc1b87583d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "bag-of-words format = list of (token_id, token_count) 2-tuples\n",
    "'''\n",
    "#  now lets create a encoded bag of words \n",
    "bow_corpus = [id2word.doc2bow(sent) for sent in processed_data_list]\n",
    "# bow_corpus[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfeb997-6e46-46c7-8d70-4741f417b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save bow corpus\n",
    "# with open('../saved_model/bow_corpus_2.txt', 'w') as f:\n",
    "#     for line in bow_corpus:\n",
    "#         f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e577f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preview BOW for our sample preprocessed document\n",
    "'''\n",
    "# Here document_num is document number 4310 which we have checked in Step 2\n",
    "# document_num = 4310\n",
    "# bow_doc_4310 = bow_corpus[document_num]\n",
    "# count = 0\n",
    "\n",
    "# for i in range(len(bow_doc_4310)):\n",
    "#     print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "#                                                      id2word[bow_doc_4310[i][0]], \n",
    "#                                                      bow_doc_4310[i][1]))\n",
    "#     count += 1\n",
    "#     if count > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a872b0a",
   "metadata": {},
   "source": [
    "### LDA - (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7912a05f-33a0-4043-94f6-a0719b9a3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba919dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading the Saved Model\n",
    "'''\n",
    "# loading model from disk\n",
    "from gensim import  models\n",
    "\n",
    "# temp_file = datapath(\"lda_model_politics_31\")\n",
    "lda_model = models.ldamodel.LdaModel.load('../saved_model/lda_model_politics_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47583120",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\n",
    "'''\n",
    "# LDA = gensim.models.ldamulticore.LdaMulticore\n",
    "# # [deprecated] lda_model = LDA(corpus=corpus_matrix,id2word=id2word, num_topics=10, random_state=100,update_every=1,chunksize=100,passes=5,alpha='auto',per_word_topics=True)\n",
    "\n",
    "# lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=40, id2word=id2word, passes=50, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c038b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For Saving  Model\n",
    "'''\n",
    "# saving model to disk.\n",
    "# [ deprecated ] temp_file = datapath(\"../../../../../../../saved_model/lda_model_politics_3\")\n",
    "# lda_model.save('../saved_model/lda_model_politics_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01595e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "'''\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic id : {}\".format(idx))\n",
    "    print(\"Words: {} \\n\".format(topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This groups the documents by their topic, for e.g\n",
    "{\n",
    "    0 : [list of documents in topic index 0]\n",
    "}\n",
    "'''\n",
    "\n",
    "cluster_by_topic = {}\n",
    "[cluster_by_topic.setdefault(i, []) for i in range(lda_model.num_topics)]\n",
    "index = 0\n",
    "for bow in bow_corpus:\n",
    "    topics_list = lda_model.get_document_topics(bow,minimum_probability=0.8)\n",
    "    for topic_id, score in topics_list: \n",
    "        cluster_by_topic[topic_id].append(index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fcd43b-2111-4762-8221-a1d67705d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda_model.num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fac1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Printing the documents that belong to a certain topic \n",
    "# '''\n",
    "for k,v in cluster_by_topic.items():\n",
    "    print (\"Topic : {}\".format(lda_model.print_topic(k)))\n",
    "    print (\"---------------------------------------------------\")\n",
    "    for index in v:\n",
    "        print (df['title'][index])\n",
    "    print (\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Getting the top 5 documents in each topics\n",
    "'''\n",
    "my_ids = [i for i in range(len(bow_corpus))]\n",
    "\n",
    "top_documents = {}\n",
    "[top_documents.setdefault(i, []) for i in range(lda_model.num_topics)]\n",
    "\n",
    "for topic_id in range(lda_model.num_topics):\n",
    "    tops = sorted(zip(my_ids, lda_model[bow_corpus]), reverse=True, key=lambda x: abs(dict(x[1]).get(topic_id, 0.0)))\n",
    "    top_five =  tops[ : 5]\n",
    "    for index, _ in top_five:\n",
    "        top_documents[topic_id].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Printing the top 5 documents in each topics\n",
    "'''\n",
    "for k,v in top_documents.items():\n",
    "    print (\"Topic : {}\".format(lda_model.print_topic(k)))\n",
    "    print (\"---------------------------------------------------\")\n",
    "    for index in v:\n",
    "        print (df['title'][index])\n",
    "    print (\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19f645-5676-4fe4-adcf-7fe006e95ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0efb21-8eda-4072-82b5-4511eab1bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus = bow_corpus, dictionary = id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312fa660",
   "metadata": {},
   "source": [
    "### LDA - (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f129520",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create tf-idf model object using models.TfidfModel on 'bow_corpus' and save it to 'tfidf'\n",
    "'''\n",
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4971c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Apply transformation to the entire corpus and call it 'corpus_tfidf'\n",
    "'''\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42027eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preview TF-IDF scores for our first document --> --> (token_id, tfidf score)\n",
    "'''\n",
    "# count = 0\n",
    "# from pprint import pprint\n",
    "# for doc in corpus_tfidf:\n",
    "#     pprint(doc)\n",
    "#     count +=1\n",
    "#     if count > 10 :\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This took more than 20 minutes so i had to stop\n",
    "It attempts to keep training lda model until the thresold is reached\n",
    "'''\n",
    "def ret_top_model():\n",
    "    \"\"\"\n",
    "    Since LDAmodel is a probabilistic model, it comes up different topics each time we run it. To control the\n",
    "    quality of the topic model we produce, we can see what the interpretability of the best topic is and keep\n",
    "    evaluating the topic model until this threshold is crossed. \n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm: Final evaluated topic model\n",
    "    top_topics: ranked topics in decreasing order. List of tuples\n",
    "    \"\"\"\n",
    "    # top_topics = [(0, 0)]\n",
    "    # while top_topics[0][1] < 0.97:\n",
    "\n",
    "    #     lm = gensim.models.LdaMulticore(bow_corpus, num_topics=20, id2word=id2word, passes=2, workers=2)\n",
    "    #     coherence_values = {}\n",
    "    #     for n, topic in lm.show_topics(num_topics=-1, formatted=False):\n",
    "    #         topic = [word for word, _ in topic]\n",
    "    #         cm = CoherenceModel(topics=[topic], texts=processed_data_list, dictionary=id2word, window_size=10)\n",
    "    #         coherence_values[n] = cm.get_coherence()\n",
    "    #     top_topics = sorted(coherence_values.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #     print(top_topics[0][1])\n",
    "    # return lm, top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd580b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm, top_topics = ret_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba42aa38",
   "metadata": {},
   "source": [
    "### HDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "688c9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import HdpModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "260c0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_model = gensim.models.HdpModel(bow_corpus, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78259fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "'''\n",
    "# for idx, topic in hdp_model.print_topics(-1):\n",
    "#     print(\"Topic: {} \\nWords: {}\".format(topic, idx ))\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a167ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_dict = {\n",
    "#     0 : \"Manoranjan\",\n",
    "#     1000 : \"Sahitya\",\n",
    "#     2000 : \"Suchana Prabhidhi\",\n",
    "#     3000 : \"Bichar\",\n",
    "#     4350 : \"Swasthya\",\n",
    "#     5000 : \"Prabas\",\n",
    "#     6000 : \"Khelkud\",\n",
    "#     7000 : \"Viswa\",\n",
    "#     8000 : \"Desh\",\n",
    "#     9000 : \"Artha\",\n",
    "# }\n",
    "# document_num = 9200 \n",
    "# print()\n",
    "# # Our test document is document number 4310\n",
    "# for k,v in document_dict.items():\n",
    "#     print(\"\\n{}\\n\".format(v))\n",
    "#     for index, score in sorted(hdp_model[bow_corpus[k]], key=lambda tup: -1*tup[1]):\n",
    "#         print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, hdp_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10dc6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Define lda model using corpus_tfidf, again using gensim.models.LdaMulticore()\n",
    "# '''\n",
    "\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=25, id2word = id2word, passes = 50, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d2fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "# '''\n",
    "# for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "#     print(\"Topic: {} Word: {}\".format(idx, topic))\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2888de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Check which topic our test document belongs to using the LDA TF-IDF model.\n",
    "# '''\n",
    "# # Our test document is document number 4310\n",
    "# for index, score in sorted(lda_model_tfidf[bow_corpus[document_num]], key=lambda tup: -1*tup[1]):\n",
    "#     print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c1f56-9c4f-4c6f-986c-64feabe967c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f375746",
   "metadata": {},
   "source": [
    "### Unseen Document Topic Identification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(columns=['body'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c3ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Unseen Document\n",
    "'''\n",
    "\n",
    "# Rajniti\n",
    "df1.loc[0] = ['''\n",
    "सन् २०२० को डिसेम्बर २९ मा हमासका सबै समूहका नेता इस्माइल हानियाले गाजाका विभिन्न सशस्त्र गुटहरूबीच \"बलियो सन्देश र एकताको सङ्केत\" को रूपमा 'स्ट्रङ पिलर' छद्म नाम दिइएको चारमध्ये पहिलो सैन्य अभ्यास गर्ने घोषणा गरे।\n",
    "\n",
    "हमास गाजाको सबैभन्दा शक्तिशाली सशस्त्र समूह थियो। अन्य १० प्यालेस्टिनी समूह पनि सम्मिलित गठबन्धन हमास प्रमुख घटक थियो। ती लडाकु समूहहरू युद्धको खेलजस्तो अभ्यासमा सहभागी भए। त्यसलाई \"संयुक्त अपरेशन कक्ष\"ले निगरानी गरेको थियो।\n",
    "\n",
    "गाजाका सशस्त्र गुटहरूसँग एउटा केन्द्रीय कमान्डअन्तर्गत समन्वय गर्न सन् २०१८ मा उक्त संरचना बनाइएको थियो।\n",
    "\n",
    "सन् २०१८ अघि हमासले प्यालेस्टिनी इस्लामिक जिहाद (पीआईजे) सँग समन्वय गरेको थियो। पीआईजे गाजाको दोस्रो ठूलो सशस्त्र गुट हो। ब्रिटेन र अन्य देशमा उक्त सङ्गठनलाई हमासलाई जसरी नै प्रतिबन्धित आतङ्कवादी सङ्गठनका रूपमा हेरिन्छ। \n",
    "\n",
    "पहिलाका द्वन्द्वमा पनि हमासले अरू समूहहरूसँग मिलेर लडाइँ गरेको थियो।\n",
    "\n",
    "तर २०२० को अभ्यासलाई धेरै समूह एकजुट भएको प्रमाणको रूपमा प्रचारबाजी गरियो।\n",
    "\n",
    "हमास नेताले पहिलो अभ्यासले सशस्त्र समूहहरूको \"स्थायी तत्परता\" प्रतिबिम्बित गरेको बताएका थिए।\n",
    "\n",
    "तीन वर्षमा गरिएका चारवटा संयुक्त अभ्यासमध्ये सन् २०२० को अभ्यास पहिलो थियो। विभिन्न सामाजिक सञ्जालहरूमा ती सबैसँग सम्बन्धित भिडिओहरू छन्।\n",
    "\n",
    "सन्देश आदानप्रदान गर्ने एप टेलिग्राममा प्रेषित फुटेजका अनुसार ‘स्ट्रङ पिलर’ अभ्यासमा सहभागी भएका पीआईजेसहित १० वटा लडाकु समूहलाई टाउकोमा बाँध्ने पट्टी र चिह्नका आधारमा बीबीसीले स्पष्टसँग पहिचान गरेको छ।  \n",
    "''' ]\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preparing the Bag of Words\n",
    "'''\n",
    "df1['body'] = df1['body'].apply(str)\n",
    "processed_new_data = string_manipulation(df1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30674ab9-37ec-4ae7-bda4-cb5a5f2f4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_new_data['body'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ee8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_new_data[\"body\"] = processed_new_data[\"body\"].apply(tokenize.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd05437-2914-45df-850f-6882a0cb0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db087fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_new_data['body'] = processed_new_data['body'].apply(lambda x : get_stem(x))\n",
    "# processed_new_data.news.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44913a-09d2-4f92-82ac-9eea7f02e422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c64b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_new_data['body'] = processed_new_data['body'].apply(lambda x : clean_data(x))\n",
    "for l in processed_new_data.body.to_list():\n",
    "    print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d23556-2ddd-4344-8354-217bbd488720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7cb9a-834f-4528-afa8-fc6cc98b89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330e066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Finds the topic and corresponding score for the unseen document \n",
    "'''\n",
    "# Data preprocessing step for the unseen document\n",
    "list_of_string = processed_new_data.body.to_list()[0] \n",
    "bow_vector = id2word.doc2bow(list_of_string)\n",
    "print(bow_vector)\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced8598-fb23-4e62-9f79-771686ce49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "topic_distribution = lda_model[bow_vector]\n",
    "topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0955519e-ec4b-4f91-bc0d-dfb1d54cf5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "topics_sorted = sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5bc9e-7057-454b-b920-dbd0f58ef5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "topics_sorted = [(i,j) for i,j in topics_sorted if j>0.42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe41c93-b9ee-4201-9fc2-021cc0f55a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "topics_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddd34e-381a-4be4-9980-67940e7da8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "topics_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c97bbf-1483-427c-a2e1-4b15460a0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "topics =['Topic-'+str(idx) for idx,score in topic_distribution if score > 0.02]\n",
    "score = [score * 100 for idx,score in topic_distribution if score > 0.02 ]\n",
    "num_bars = len(topic_distribution)\n",
    "random_colors = [np.random.rand(3,) for _ in range(num_bars)]\n",
    "\n",
    "ax.bar(topics, score,color=random_colors)\n",
    "\n",
    "ax.set_ylabel('Topic percentage in Document')\n",
    "ax.set_title('Constituent percentage of topics in a Document')\n",
    "ax.legend(title='Percentage')\n",
    "\n",
    "plt.savefig('topics.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ac6f8-6620-4b46-81a3-a30cd08c1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "x = dict(lda_model.show_topic(0,20))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df9706-11cd-45da-bace-01f66e3471d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dc648-1278-460b-8488-108026046805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "plt.axis('off')\n",
    "plt.imshow(WordCloud(font_path=\"../resources/Mangal.ttf\").fit_words(x))\n",
    "plt.savefig('image.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a34be0-ed2c-41bc-9582-0113cb64a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "lda_model.print_topic(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f650f",
   "metadata": {},
   "source": [
    "### Document Similarity - JensenShanon Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcbf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf084b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Obtaining the topic distribution of every document\n",
    "'''\n",
    "doc_topic_dist = []\n",
    "count = 0\n",
    "for bow in bow_corpus:\n",
    "    topics_list = lda_model.get_document_topics(bow,minimum_probability=0)\n",
    "    # print(topics_list)\n",
    "    # print(len(topics_list))\n",
    "    # if count > 2:\n",
    "    #     break\n",
    "    # count += 1\n",
    "    row = []\n",
    "    for idx, score in topics_list:\n",
    "        row.append(score)\n",
    "\n",
    "    doc_topic_dist.append(row)\n",
    "\n",
    "print(len(doc_topic_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_distribution = np.array(doc_topic_dist)\n",
    "doc_distribution[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4e043-262a-4067-8a77-022619bf78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(doc_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34020acd-2146-4c3c-b4c8-f0b8bda7c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv [ check this code if works, as i modified this one ]\n",
    "# df_temp.to_csv('../saved_model/doc_topic_distribution_39k.csv',index=False,index_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f438e7-45bb-4975-96c9-0479b5f3f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from csv\n",
    "df_temp = pd.read_csv('../saved_model/doc_topic_distribution_39k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672867ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dist = []\n",
    "for idx,score in lda_model.get_document_topics(bow_vector, minimum_probability=0):\n",
    "    new_dist.append(score)\n",
    "\n",
    "new_doc_distribution = np.array(new_dist)\n",
    "new_doc_distribution.shape\n",
    "# new_doc_distribution = np.array([tup[1] for tup in lda_model[bow_vector]])\n",
    "# new_doc_distribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def jensen_shannon(query, matrix):\n",
    "#     \"\"\"\n",
    "#     This function implements a Jensen-Shannon similarity\n",
    "#     between the input query (an LDA topic distribution for a document)\n",
    "#     and the entire corpus of topic distributions.\n",
    "#     It returns an array of length M where M is the number of documents in the corpus\n",
    "#     \"\"\"\n",
    "#     # lets keep with the p,q notation above\n",
    "#     p = query[None,:].T # take transpose\n",
    "#     q = matrix.T # transpose matrix\n",
    "#     m = 0.5*(p + q)\n",
    "#     return np.sqrt(0.5*(entropy(p,m) + entropy(q,m)))\n",
    "\n",
    "def jensen_shannon(query, matrix):\n",
    "    \"\"\"\n",
    "    This function implements a Jensen-Shannon similarity\n",
    "    between the input query (an LDA topic distribution for a document)\n",
    "    and the entire corpus of topic distributions.\n",
    "    \"\"\"\n",
    "    sim = [distance.jensenshannon(data,query) for data in matrix]\n",
    "    return np.array(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91002e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_documents(query,matrix,k=10):\n",
    "    \"\"\"\n",
    "    This function implements the Jensen-Shannon distance above\n",
    "    and retruns the top k indices of the smallest jensen shannon distances\n",
    "    \"\"\"\n",
    "    sims = jensen_shannon(query,matrix) # list of jensen shannon distances\n",
    "    return sims.argsort()[:k] # the top k positional index of the smallest Jensen Shannon distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd60066",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sim_ids = get_most_similar_documents(new_doc_distribution, doc_distribution)\n",
    "print(most_sim_ids)\n",
    "for ids in most_sim_ids:\n",
    "    print(df['title'][ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36cf77-a44d-4769-9411-29e37ae8f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'][12,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118820a-b85f-4a3a-ad5f-44a03948bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a284f-ff36-4f5b-9168-9274075c50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('../backend/generated_info/top_news_per_topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ed71d-707f-4910-9465-1a5135c43736",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in range(40):\n",
    "    d[i] = np.array(news_df[news_df['topic_no']==i]['topic_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c5b4d-30e0-4638-b64e-68fc9786b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in d.items():\n",
    "    print(i,'--->',len(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317f4be-927c-4274-85b6-19351b57851b",
   "metadata": {},
   "outputs": [],
   "source": [
    " c= news_df[news_df['topic_no']==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8755e3-c19b-4778-812d-67dbdd5a568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f885a-3549-4383-8768-5ca6d498e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68899f36-99d0-4961-bc3f-c237c28f0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.iloc[1*8:1*8+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd8795-0c11-47c8-9393-8c7fd9dfb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = news_df.iloc[13*8:13*8+8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac2091-4089-43af-aa5f-6fb48c01c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b98da-8fed-4456-ada4-a8dc390123e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024ed55-9eb3-4729-9a9e-d3bf4c7935b0",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e0b41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e868098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = processed_data.body.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cea8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=50,\n",
    "                                           )\n",
    "    \n",
    "    \n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c70f527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5851772476421515\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=text, dictionary=id2word, coherence='c_v')\n",
    "print(coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b10c21ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5584423796438815\n"
     ]
    }
   ],
   "source": [
    "\n",
    "coherence_model_hdp = CoherenceModel(model=hdp_model, texts=text, dictionary=id2word, coherence='c_v')\n",
    "print(coherence_model_hdp.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "291fb588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6183861178543825\n"
     ]
    }
   ],
   "source": [
    "cv = compute_coherence_values(corpus=bow_corpus, dictionary=id2word, k=23)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28b84e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/240 [18:18<?, ?it/s]\n",
      "  0%|          | 1/240 [07:18<29:06:35, 438.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6197678986326711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/240 [14:57<29:48:17, 450.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6024341272613191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3/240 [23:09<30:54:32, 469.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6087154870920156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# iterate through number of topics\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m topics_range:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# get the coherence score for the given parameters\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_coherence_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbow_corpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid2word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Save the model results\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cv)\n",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m, in \u001b[0;36mcompute_coherence_values\u001b[0;34m(corpus, dictionary, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_coherence_values\u001b[39m(corpus, dictionary, k):\n\u001b[0;32m----> 4\u001b[0m     lda_model \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaMulticore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     coherence_model_lda \u001b[38;5;241m=\u001b[39m CoherenceModel(model\u001b[38;5;241m=\u001b[39mlda_model, texts\u001b[38;5;241m=\u001b[39mtext, dictionary\u001b[38;5;241m=\u001b[39mid2word, coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_v\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m coherence_model_lda\u001b[38;5;241m.\u001b[39mget_coherence()\n",
      "File \u001b[0;32m~/dev/projects/topic_modeling/env/lib/python3.10/site-packages/gensim/models/ldamulticore.py:186\u001b[0m, in \u001b[0;36mLdaMulticore.__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(alpha, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m alpha \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLdaMulticore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_topics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid2word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimum_probability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminimum_probability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminimum_phi_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminimum_phi_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_word_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_word_topics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/projects/topic_modeling/env/lib/python3.10/site-packages/gensim/models/ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    520\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m )\n",
      "File \u001b[0;32m~/dev/projects/topic_modeling/env/lib/python3.10/site-packages/gensim/models/ldamulticore.py:316\u001b[0m, in \u001b[0;36mLdaMulticore.update\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# endfor single corpus pass\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# wait for all outstanding jobs to finish\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m queue_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m     \u001b[43mprocess_result_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reallen \u001b[38;5;241m!=\u001b[39m lencorpus:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput corpus size changed during training (don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use generators as input)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/projects/topic_modeling/env/lib/python3.10/site-packages/gensim/models/ldamulticore.py:283\u001b[0m, in \u001b[0;36mLdaMulticore.update.<locals>.process_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    281\u001b[0m other\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_every \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (force \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_updates \u001b[38;5;241m/\u001b[39m updateafter) \u001b[38;5;241m%\u001b[39m eval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_docs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlencorpus\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/projects/topic_modeling/env/lib/python3.10/site-packages/gensim/models/ldamodel.py:847\u001b[0m, in \u001b[0;36mLdaModel.log_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    845\u001b[0m corpus_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(cnt \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m chunk \u001b[38;5;28;01mfor\u001b[39;00m _, cnt \u001b[38;5;129;01min\u001b[39;00m document)\n\u001b[1;32m    846\u001b[0m subsample_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m total_docs \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[0;32m--> 847\u001b[0m perwordbound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsample_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubsample_ratio\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m (subsample_ratio \u001b[38;5;241m*\u001b[39m corpus_words)\n\u001b[1;32m    848\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m per-word bound, \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;124m perplexity estimate based on a held-out corpus of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m documents with \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m words\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    850\u001b[0m     perwordbound, np\u001b[38;5;241m.\u001b[39mexp2(\u001b[38;5;241m-\u001b[39mperwordbound), \u001b[38;5;28mlen\u001b[39m(chunk), corpus_words\n\u001b[1;32m    851\u001b[0m )\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m perwordbound\n",
      "File \u001b[0;32m~/dev/projects/topic_modeling/env/lib/python3.10/site-packages/gensim/models/ldamodel.py:1113\u001b[0m, in \u001b[0;36mLdaModel.bound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbound: at document #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, d)\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1113\u001b[0m     gammad, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m     gammad \u001b[38;5;241m=\u001b[39m gamma[d]\n",
      "File \u001b[0;32m~/dev/projects/topic_modeling/env/lib/python3.10/site-packages/gensim/models/ldamodel.py:724\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    722\u001b[0m phinorm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(expElogthetad, expElogbetad) \u001b[38;5;241m+\u001b[39m epsilon\n\u001b[1;32m    723\u001b[0m \u001b[38;5;66;03m# If gamma hasn't changed much, we're done.\u001b[39;00m\n\u001b[0;32m--> 724\u001b[0m meanchange \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgammad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlastgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meanchange \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_threshold:\n\u001b[1;32m    726\u001b[0m     converged \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 23\n",
    "max_topics = 25\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(bow_corpus)\n",
    "corpus_sets = [gensim.utils.ClippedCorpus(bow_corpus, int(num_of_docs*0.75)), \n",
    "               bow_corpus]\n",
    "\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(len(topics_range))\n",
    "    \n",
    "    # iterate through number of topics\n",
    "    for k in topics_range:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=bow_corpus, dictionary=id2word, \n",
    "                                        k=k)\n",
    "        # Save the model results\n",
    "        print(cv)\n",
    "        \n",
    "        pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e11bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=text, dictionary=id2word, coherence='c_v')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
